{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Customer Churn Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set_style('darkgrid')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data Preparation based on EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def datapreparation(filepath):\n",
    "    \n",
    "    df = pd.read_csv(filepath)\n",
    "    df.drop([\"customerID\"], inplace = True, axis = 1)\n",
    "    \n",
    "    df.TotalCharges = df.TotalCharges.replace(\" \",np.nan)\n",
    "    df.TotalCharges.fillna(0, inplace = True)\n",
    "    df.TotalCharges = df.TotalCharges.astype(float)\n",
    "    \n",
    "    cols1 = ['Partner', 'Dependents', 'PaperlessBilling', 'Churn', 'PhoneService']\n",
    "    for col in cols1:\n",
    "        df[col] = df[col].apply(lambda x: 0 if x == \"No\" else 1)\n",
    "   \n",
    "    df.gender = df.gender.apply(lambda x: 0 if x == \"Male\" else 1)\n",
    "    df.MultipleLines = df.MultipleLines.map({'No phone service': 0, 'No': 0, 'Yes': 1})\n",
    "    \n",
    "    cols2 = ['OnlineSecurity', 'OnlineBackup', 'DeviceProtection', 'TechSupport', 'StreamingTV', 'StreamingMovies']\n",
    "    for col in cols2:\n",
    "        df[col] = df[col].map({'No internet service': 0, 'No': 0, 'Yes': 1})\n",
    "    \n",
    "    df = pd.get_dummies(df, columns=['InternetService', 'Contract', 'PaymentMethod'], drop_first=True)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bgowt\\AppData\\Local\\Temp\\ipykernel_1172\\562632756.py:7: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df.TotalCharges.fillna(0, inplace = True)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gender</th>\n",
       "      <th>SeniorCitizen</th>\n",
       "      <th>Partner</th>\n",
       "      <th>Dependents</th>\n",
       "      <th>tenure</th>\n",
       "      <th>PhoneService</th>\n",
       "      <th>MultipleLines</th>\n",
       "      <th>OnlineSecurity</th>\n",
       "      <th>OnlineBackup</th>\n",
       "      <th>DeviceProtection</th>\n",
       "      <th>...</th>\n",
       "      <th>MonthlyCharges</th>\n",
       "      <th>TotalCharges</th>\n",
       "      <th>Churn</th>\n",
       "      <th>InternetService_Fiber optic</th>\n",
       "      <th>InternetService_No</th>\n",
       "      <th>Contract_One year</th>\n",
       "      <th>Contract_Two year</th>\n",
       "      <th>PaymentMethod_Credit card (automatic)</th>\n",
       "      <th>PaymentMethod_Electronic check</th>\n",
       "      <th>PaymentMethod_Mailed check</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>29.85</td>\n",
       "      <td>29.85</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>34</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>56.95</td>\n",
       "      <td>1889.50</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>53.85</td>\n",
       "      <td>108.15</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>45</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>42.30</td>\n",
       "      <td>1840.75</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>70.70</td>\n",
       "      <td>151.65</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   gender  SeniorCitizen  Partner  Dependents  tenure  PhoneService  \\\n",
       "0       1              0        1           0       1             0   \n",
       "1       0              0        0           0      34             1   \n",
       "2       0              0        0           0       2             1   \n",
       "3       0              0        0           0      45             0   \n",
       "4       1              0        0           0       2             1   \n",
       "\n",
       "   MultipleLines  OnlineSecurity  OnlineBackup  DeviceProtection  ...  \\\n",
       "0              0               0             1                 0  ...   \n",
       "1              0               1             0                 1  ...   \n",
       "2              0               1             1                 0  ...   \n",
       "3              0               1             0                 1  ...   \n",
       "4              0               0             0                 0  ...   \n",
       "\n",
       "   MonthlyCharges  TotalCharges  Churn  InternetService_Fiber optic  \\\n",
       "0           29.85         29.85      0                        False   \n",
       "1           56.95       1889.50      0                        False   \n",
       "2           53.85        108.15      1                        False   \n",
       "3           42.30       1840.75      0                        False   \n",
       "4           70.70        151.65      1                         True   \n",
       "\n",
       "   InternetService_No  Contract_One year  Contract_Two year  \\\n",
       "0               False              False              False   \n",
       "1               False               True              False   \n",
       "2               False              False              False   \n",
       "3               False               True              False   \n",
       "4               False              False              False   \n",
       "\n",
       "   PaymentMethod_Credit card (automatic)  PaymentMethod_Electronic check  \\\n",
       "0                                  False                            True   \n",
       "1                                  False                           False   \n",
       "2                                  False                           False   \n",
       "3                                  False                           False   \n",
       "4                                  False                            True   \n",
       "\n",
       "   PaymentMethod_Mailed check  \n",
       "0                       False  \n",
       "1                        True  \n",
       "2                        True  \n",
       "3                       False  \n",
       "4                       False  \n",
       "\n",
       "[5 rows x 24 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = datapreparation(filepath = \"data.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.False_"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().any().any()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Building"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I am going to build and tune random forest model because in this case tree based method would perform better. I am also interested in individual customer's churning probability and in understanding how the model calculates it using Shap values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, classification_report\n",
    "from sklearn.metrics import roc_auc_score, roc_curve, precision_score, recall_score, f1_score\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = train_test_split(df, test_size=0.2, random_state=111, stratify = df.Churn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = df.columns[df.columns!=\"Churn\"]\n",
    "y = \"Churn\"\n",
    "train_x = train[x]\n",
    "train_y = train[y]\n",
    "test_x = test[x]\n",
    "test_y = test[y]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function for model fitting\n",
    "def churn_prediction(algo, training_x, training_y, testing_x, testing_y, cols, cf = 'coefficients'):\n",
    "    algo.fit(training_x,training_y)\n",
    "    predictions = algo.predict(testing_x)\n",
    "    probabilities = algo.predict_proba(testing_x)[:,1]\n",
    "    \n",
    "    #coeffs\n",
    "    if cf == \"coefficients\":\n",
    "        coefficients = pd.DataFrame(algo.coef_.ravel())\n",
    "    elif cf == \"features\":\n",
    "        coefficients = pd.DataFrame(algo.feature_importances_)\n",
    "        \n",
    "    column_df = pd.DataFrame(cols)\n",
    "    coef_sumry = (pd.merge(coefficients,column_df,left_index= True,\n",
    "                              right_index= True, how = \"left\"))\n",
    "    coef_sumry.columns = [\"coefficients\",\"features\"]\n",
    "    coef_sumry = coef_sumry.sort_values(by = \"coefficients\",ascending = False)\n",
    "    \n",
    "    print (algo)\n",
    "    print (\"\\n Classification report : \\n\",classification_report(testing_y,predictions))\n",
    "    print (\"Accuracy   Score : \",accuracy_score(testing_y,predictions))\n",
    "    \n",
    "    #confusion matrix\n",
    "    conf_matrix = confusion_matrix(testing_y,predictions)\n",
    "    plt.figure(figsize=(12,12))\n",
    "    plt.subplot(221)\n",
    "    sns.heatmap(conf_matrix, fmt = \"d\",annot=True, cmap='Blues')\n",
    "    plt.title('Confuion Matrix')\n",
    "    plt.ylabel('True Values')\n",
    "    plt.xlabel('Predicted Values')\n",
    "    \n",
    "    #roc_auc_score\n",
    "    model_roc_auc = roc_auc_score(testing_y,probabilities) \n",
    "    print (\"Area under curve : \",model_roc_auc,\"\\n\")\n",
    "    fpr,tpr,thresholds = roc_curve(testing_y,probabilities)\n",
    "    \n",
    "    plt.subplot(222)\n",
    "    plt.plot(fpr, tpr, color='darkorange', lw=1, label = \"Auc : %.3f\" %model_roc_auc)\n",
    "    plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('Receiver operating characteristic')\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    \n",
    "    plt.subplot(212)\n",
    "    sns.barplot(x = coef_sumry[\"features\"] ,y = coef_sumry[\"coefficients\"])\n",
    "    plt.title('Feature Importances')\n",
    "    plt.xticks(rotation=\"vertical\")\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameters Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Grid 1: Selecting class weight and estimators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid1 = {'max_features':['auto', 'sqrt', 'log2', None],\n",
    "          'n_estimators':[300, 500, 700, 900, 1100, 1300]\n",
    "         }\n",
    "\n",
    "rf_model = RandomForestClassifier()\n",
    "grid1 = GridSearchCV(estimator=rf_model, param_grid=param_grid1, n_jobs=-1, cv=3, verbose=1, scoring = 'f1')\n",
    "grid1.fit(train_x, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid1.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt = pd.DataFrame(grid1.cv_results_)\n",
    "dt.param_max_features = dt.param_max_features.astype(str)\n",
    "dt.param_n_estimators = dt.param_n_estimators.astype(str)\n",
    "\n",
    "table = pd.pivot_table(dt, values='mean_test_score', index='param_n_estimators', \n",
    "                       columns='param_max_features')\n",
    "     \n",
    "sns.heatmap(table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid1.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Grid 2: Selecting max depth and split criterion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid2 = {'max_features':['sqrt', 'log2', None],\n",
    "          'n_estimators':[1000, 1100, 1200],\n",
    "           'criterion': ['entropy', 'gini'],    \n",
    "          'max_depth': [7, 9, 11, 13, 15, None],\n",
    "         }\n",
    "\n",
    "rf_model = RandomForestClassifier()\n",
    "grid2 = GridSearchCV(estimator=rf_model, param_grid=param_grid2, n_jobs=-1, cv=3, verbose=1, scoring = 'f1')\n",
    "grid2.fit(train_x, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid2.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt = pd.DataFrame(grid2.cv_results_)\n",
    "\n",
    "table = pd.pivot_table(dt, values='mean_test_score', index='param_max_depth', \n",
    "                       columns='param_criterion')\n",
    "     \n",
    "sns.heatmap(table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table = pd.pivot_table(dt, values='mean_test_score', index='param_max_depth', \n",
    "                       columns='param_n_estimators')\n",
    "     \n",
    "sns.heatmap(table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid2.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checking if other depth and estimator value results better"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid2_2 = {\n",
    "    'max_features': ['sqrt', 'log2', None],   \n",
    "    'n_estimators': [950, 1000, 1050],\n",
    "    'criterion': ['gini'],                  \n",
    "    'max_depth': [10, 11, 12],\n",
    "}\n",
    "\n",
    "\n",
    "rf_model = RandomForestClassifier()\n",
    "grid2_2 = GridSearchCV(estimator=rf_model, param_grid=param_grid2_2, n_jobs=-1, cv=3, verbose=1, scoring = 'f1')\n",
    "grid2_2.fit(train_x, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid2_2.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid2_2.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Grid 3: Selecting minimum samples leaf and split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid3 = {\n",
    "    'max_features': ['sqrt', 'log2', None],   \n",
    "    'n_estimators': [1000],\n",
    "    'criterion': ['gini'],               \n",
    "    'max_depth': [10],\n",
    "    'min_samples_leaf': [1, 3, 5, 7],\n",
    "    'min_samples_split': [2, 4, 6, 8],\n",
    "}\n",
    "\n",
    "rf_model = RandomForestClassifier()\n",
    "grid3 = GridSearchCV(estimator=rf_model, param_grid=param_grid3, n_jobs=-1, cv=3, verbose=1, scoring = 'f1')\n",
    "grid3.fit(train_x, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid3.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt = pd.DataFrame(grid3.cv_results_)\n",
    "\n",
    "table = pd.pivot_table(dt, values='mean_test_score', index='param_min_samples_leaf', \n",
    "                       columns='param_min_samples_split')\n",
    "     \n",
    "sns.heatmap(table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid3.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Grid 4: Selecting class weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid4 = {'class_weight':[{0:1, 1:1}, {0:1, 1:2}, {0:1, 1:3}],\n",
    "            'max_features':['sqrt', 'log2', None],\n",
    "          'n_estimators':[1000],\n",
    "           'criterion': ['gini'],    \n",
    "          'max_depth': [10],\n",
    "          'min_samples_leaf': [1],\n",
    "          'min_samples_split': [8]\n",
    "         }\n",
    "\n",
    "rf_model = RandomForestClassifier()\n",
    "grid4 = GridSearchCV(estimator=rf_model, param_grid=param_grid4, n_jobs=-1, cv=3, verbose=1, scoring = 'f1')\n",
    "grid4.fit(train_x, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid4.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt = pd.DataFrame(grid4.cv_results_)\n",
    "dt.param_class_weight = dt.param_class_weight.astype(str)\n",
    "table = pd.pivot_table(dt, values='mean_test_score', index='param_class_weight')\n",
    "     \n",
    "sns.heatmap(table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid4.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Final Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "model = RandomForestClassifier(\n",
    "    bootstrap=True,\n",
    "    ccp_alpha=0.0,\n",
    "    class_weight={0: 1, 1: 2},\n",
    "    criterion=\"gini\",\n",
    "    max_depth=10,\n",
    "    max_features=\"sqrt\",   # ✅ replaces 'auto'\n",
    "    min_samples_leaf=1,\n",
    "    min_samples_split=8,\n",
    "    n_estimators=1000,\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "churn_prediction(model, train_x, train_y, test_x, test_y, x,\"features\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checking the model's performance on train data itself"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_scores = cross_val_score(model, train_x, train_y, cv = 5, scoring='f1')\n",
    "train_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(train_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see that the performance of the model on test data is same as training data. So, we can conclude that there is no overfitting and underfitting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Saving model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "pickle.dump(model, open('model.pkl','wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explaining the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import eli5\n",
    "from eli5.sklearn import PermutationImportance\n",
    "\n",
    "from pdpbox import pdp, info_plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "perm = PermutationImportance(model, random_state=1).fit(test_x, test_y)\n",
    "eli5.show_weights(perm, feature_names = test_x.columns.tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Shap Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shap \n",
    "shap.initjs()\n",
    "\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "explainer = shap.TreeExplainer(model)\n",
    "\n",
    "X_one = test_x.iloc[[0]]  # 2D\n",
    "shap_values = explainer.shap_values(X_one)\n",
    "\n",
    "# Case A: shap_values is a list (per class)\n",
    "if isinstance(shap_values, list):\n",
    "    shap.initjs()\n",
    "    shap.force_plot(explainer.expected_value[1], shap_values[1][0], X_one.iloc[0], matplotlib=True)\n",
    "\n",
    "# Case B: shap_values is an array (may be 3D)\n",
    "else:\n",
    "    shap.initjs()\n",
    "    # if shape is (1, n_features, n_classes) take class 1\n",
    "    if len(shap_values.shape) == 3:\n",
    "        sv_class1 = shap_values[0, :, 1]\n",
    "        base = explainer.expected_value[1] if hasattr(explainer.expected_value, \"__len__\") else explainer.expected_value\n",
    "        shap.force_plot(base, sv_class1, X_one.iloc[0], matplotlib=True)\n",
    "    else:\n",
    "        # (1, n_features) binary already\n",
    "        base = explainer.expected_value\n",
    "        shap.force_plot(base, shap_values[0], X_one.iloc[0], matplotlib=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving Explainer\n",
    "ex_filename = 'explainer.bz2'\n",
    "joblib.dump(explainer, filename=ex_filename, compress=('bz2', 9))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "explainer = joblib.load(\"explainer.bz2\")\n",
    "\n",
    "# keep 2D dataframe\n",
    "X_one = test_x.iloc[[0]]\n",
    "\n",
    "shap_values = explainer.shap_values(X_one)\n",
    "\n",
    "# ---- make shap vector for class 1 safely ----\n",
    "if isinstance(shap_values, list):\n",
    "    # older SHAP format: list per class\n",
    "    sv = shap_values[1][0]\n",
    "    base = explainer.expected_value[1]\n",
    "elif shap_values.ndim == 3:\n",
    "    # newer format: (n_samples, n_features, n_classes)\n",
    "    sv = shap_values[0, :, 1]\n",
    "    base = explainer.expected_value[1] if hasattr(explainer.expected_value, \"__len__\") else explainer.expected_value\n",
    "else:\n",
    "    # binary format: (n_samples, n_features)\n",
    "    sv = shap_values[0]\n",
    "    base = explainer.expected_value if not hasattr(explainer.expected_value, \"__len__\") else explainer.expected_value[0]\n",
    "\n",
    "# ---- plot + save ----\n",
    "shap.force_plot(\n",
    "    base,\n",
    "    sv,\n",
    "    X_one.iloc[0],          # feature values (Series)\n",
    "    matplotlib=True,\n",
    "    show=False\n",
    ")\n",
    "\n",
    "plt.savefig(\"static/images/shap.png\", bbox_inches=\"tight\", dpi=200)\n",
    "plt.show()\n",
    "plt.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gauge Chart "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.patches import Circle, Wedge, Rectangle\n",
    "\n",
    "def degree_range(n): \n",
    "    start = np.linspace(0,180,n+1, endpoint=True)[0:-1]\n",
    "    end = np.linspace(0,180,n+1, endpoint=True)[1::]\n",
    "    mid_points = start + ((end-start)/2.)\n",
    "    return np.c_[start, end], mid_points\n",
    "\n",
    "def rot_text(ang): \n",
    "    rotation = np.degrees(np.radians(ang) * np.pi / np.pi - np.radians(90))\n",
    "    return rotation\n",
    "\n",
    "def gauge(labels=['LOW','MEDIUM','HIGH','EXTREME'], \\\n",
    "          colors=['#007A00','#0063BF','#FFCC00','#ED1C24'], Probability=1, fname=False): \n",
    "    \n",
    "    N = len(labels)\n",
    "    colors = colors[::-1]\n",
    "\n",
    "    \"\"\"\n",
    "    begins the plotting\n",
    "    \"\"\"\n",
    "    \n",
    "    fig, ax = plt.subplots()\n",
    "\n",
    "    ang_range, mid_points = degree_range(4)\n",
    "\n",
    "    labels = labels[::-1]\n",
    "    \n",
    "    \"\"\"\n",
    "    plots the sectors and the arcs\n",
    "    \"\"\"\n",
    "    patches = []\n",
    "    for ang, c in zip(ang_range, colors): \n",
    "        # sectors\n",
    "        patches.append(Wedge((0.,0.), .4, *ang, facecolor='w', lw=2))\n",
    "        # arcs\n",
    "        patches.append(Wedge((0.,0.), .4, *ang, width=0.10, facecolor=c, lw=2, alpha=0.5))\n",
    "    \n",
    "    [ax.add_patch(p) for p in patches]\n",
    "\n",
    "    \n",
    "    \"\"\"\n",
    "    set the labels (e.g. 'LOW','MEDIUM',...)\n",
    "    \"\"\"\n",
    "\n",
    "    for mid, lab in zip(mid_points, labels): \n",
    "\n",
    "        ax.text(0.35 * np.cos(np.radians(mid)), 0.35 * np.sin(np.radians(mid)), lab, \\\n",
    "            horizontalalignment='center', verticalalignment='center', fontsize=14, \\\n",
    "            fontweight='bold', rotation = rot_text(mid))\n",
    "\n",
    "    \"\"\"\n",
    "    set the bottom banner and the title\n",
    "    \"\"\"\n",
    "    r = Rectangle((-0.4,-0.1),0.8,0.1, facecolor='w', lw=2)\n",
    "    ax.add_patch(r)\n",
    "    \n",
    "    ax.text(0, -0.05, 'Churn Probability ' + np.round(Probability,2).astype(str), horizontalalignment='center', \\\n",
    "         verticalalignment='center', fontsize=22, fontweight='bold')\n",
    "\n",
    "    \"\"\"\n",
    "    plots the arrow now\n",
    "    \"\"\"\n",
    "    \n",
    "    pos = (1-Probability)*180\n",
    "    ax.arrow(0, 0, 0.225 * np.cos(np.radians(pos)), 0.225 * np.sin(np.radians(pos)), \\\n",
    "                 width=0.04, head_width=0.09, head_length=0.1, fc='k', ec='k')\n",
    "    \n",
    "    ax.add_patch(Circle((0, 0), radius=0.02, facecolor='k'))\n",
    "    ax.add_patch(Circle((0, 0), radius=0.01, facecolor='w', zorder=11))\n",
    "\n",
    "    \"\"\"\n",
    "    removes frame and ticks, and makes axis equal and tight\n",
    "    \"\"\"\n",
    "    \n",
    "    ax.set_frame_on(False)\n",
    "    ax.axes.set_xticks([])\n",
    "    ax.axes.set_yticks([])\n",
    "    ax.axis('equal')\n",
    "    plt.tight_layout()\n",
    "    if fname:\n",
    "        fig.savefig(fname, dpi=200, bbox_inches=\"tight\")\n",
    "\n",
    "    plt.show()\n",
    "    return fig, ax\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "test_x_aligned = test_x.reindex(columns=train_x.columns, fill_value=0)\n",
    "prob = model.predict_proba(test_x_aligned.iloc[[0]])[0, 1]\n",
    "gauge(Probability=float(prob))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Final Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "test_x.columns"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (survival)",
   "language": "python",
   "name": "survival"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
